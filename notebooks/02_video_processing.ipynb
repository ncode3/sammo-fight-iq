{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f010b21f-19d7-4f26-8b1a-ec3357008bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: /opt/app-root/src/sammo-fight-iq\n",
      "Video path: /opt/app-root/src/sammo-fight-iq/data/round1.mp4\n",
      "Exists: True\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Figure out where this notebook is running\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "print(\"CWD:\", NOTEBOOK_DIR)\n",
    "\n",
    "# If we're in .../sammo-fight-iq/notebooks, project root is the parent\n",
    "if NOTEBOOK_DIR.name == \"notebooks\":\n",
    "    PROJECT_ROOT = NOTEBOOK_DIR.parent\n",
    "else:\n",
    "    PROJECT_ROOT = NOTEBOOK_DIR\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "VIDEO_PATH = DATA_DIR / \"round1.mp4\"\n",
    "\n",
    "print(\"Video path:\", VIDEO_PATH)\n",
    "print(\"Exists:\", VIDEO_PATH.exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad7d7bde-aaa3-4c98-b069-2309251fa83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper ready.\n"
     ]
    }
   ],
   "source": [
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "def frame_boxing_metrics(landmarks, mp_pose=mp_pose):\n",
    "    \"\"\"Compute basic boxing metrics from one frame using pose landmarks.\"\"\"\n",
    "    lmk = landmarks\n",
    "\n",
    "    left_shoulder  = lmk[mp_pose.PoseLandmark.LEFT_SHOULDER]\n",
    "    right_shoulder = lmk[mp_pose.PoseLandmark.RIGHT_SHOULDER]\n",
    "    left_wrist     = lmk[mp_pose.PoseLandmark.LEFT_WRIST]\n",
    "    right_wrist    = lmk[mp_pose.PoseLandmark.RIGHT_WRIST]\n",
    "    left_hip       = lmk[mp_pose.PoseLandmark.LEFT_HIP]\n",
    "    right_hip      = lmk[mp_pose.PoseLandmark.RIGHT_HIP]\n",
    "    nose           = lmk[mp_pose.PoseLandmark.NOSE]\n",
    "\n",
    "    # Guard height = wrist relative to shoulder (lower = tighter guard)\n",
    "    left_guard_height  = left_wrist.y  - left_shoulder.y\n",
    "    right_guard_height = right_wrist.y - right_shoulder.y\n",
    "\n",
    "    # Simple hip rotation + stance width (x-distance between hips)\n",
    "    hip_rotation = abs(left_hip.x - right_hip.x)\n",
    "    stance_width = abs(left_hip.x - right_hip.x)\n",
    "\n",
    "    return {\n",
    "        \"left_guard_height\":  left_guard_height,\n",
    "        \"right_guard_height\": right_guard_height,\n",
    "        \"head_y\":             nose.y,\n",
    "        \"hip_rotation\":       hip_rotation,\n",
    "        \"stance_width\":       stance_width,\n",
    "    }\n",
    "\n",
    "print(\"Helper ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e524ed72-dbdf-459c-845a-88221e5423cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1763222430.895003    1961 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1763222430.933193    1961 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "/opt/app-root/lib64/python3.12/site-packages/google/protobuf/symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames processed: 14095\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left_guard_height</th>\n",
       "      <th>right_guard_height</th>\n",
       "      <th>head_y</th>\n",
       "      <th>hip_rotation</th>\n",
       "      <th>stance_width</th>\n",
       "      <th>pose_detected</th>\n",
       "      <th>frame</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.014106</td>\n",
       "      <td>0.037065</td>\n",
       "      <td>0.128473</td>\n",
       "      <td>0.001398</td>\n",
       "      <td>0.001398</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.051068</td>\n",
       "      <td>0.010931</td>\n",
       "      <td>0.142394</td>\n",
       "      <td>0.044306</td>\n",
       "      <td>0.044306</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   left_guard_height  right_guard_height    head_y  hip_rotation  \\\n",
       "0                NaN                 NaN       NaN           NaN   \n",
       "1                NaN                 NaN       NaN           NaN   \n",
       "2                NaN                 NaN       NaN           NaN   \n",
       "3           0.014106            0.037065  0.128473      0.001398   \n",
       "4          -0.051068            0.010931  0.142394      0.044306   \n",
       "\n",
       "   stance_width  pose_detected  frame  \n",
       "0           NaN          False      1  \n",
       "1           NaN          False      2  \n",
       "2           NaN          False      3  \n",
       "3      0.001398           True      4  \n",
       "4      0.044306           True      5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pose = mp_pose.Pose(\n",
    "    static_image_mode=False,\n",
    "    model_complexity=1,\n",
    "    enable_segmentation=False,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5,\n",
    ")\n",
    "\n",
    "cap = cv2.VideoCapture(str(VIDEO_PATH))\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(f\"Could not open video: {VIDEO_PATH}\")\n",
    "\n",
    "frame_idx = 0\n",
    "rows = []\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_idx += 1\n",
    "\n",
    "    # BGR → RGB for Mediapipe\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(rgb)\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "        metrics = frame_boxing_metrics(results.pose_landmarks.landmark)\n",
    "        metrics[\"pose_detected\"] = True\n",
    "    else:\n",
    "        metrics = {\n",
    "            \"left_guard_height\": np.nan,\n",
    "            \"right_guard_height\": np.nan,\n",
    "            \"head_y\": np.nan,\n",
    "            \"hip_rotation\": np.nan,\n",
    "            \"stance_width\": np.nan,\n",
    "            \"pose_detected\": False,\n",
    "        }\n",
    "\n",
    "    metrics[\"frame\"] = frame_idx\n",
    "    rows.append(metrics)\n",
    "\n",
    "cap.release()\n",
    "pose.close()\n",
    "\n",
    "frame_df = pd.DataFrame(rows)\n",
    "print(\"Frames processed:\", len(frame_df))\n",
    "frame_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15a16947-9d20-4140-9fb2-6cc427665ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "round_id                    round1\n",
       "total_frames                 14095\n",
       "pose_frames                   8520\n",
       "pose_coverage              0.60447\n",
       "guard_down_ratio          0.010329\n",
       "avg_left_guard_height     0.031025\n",
       "avg_right_guard_height     0.03553\n",
       "avg_hip_rotation           0.04255\n",
       "avg_stance_width           0.04255\n",
       "avg_head_y                0.630725\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = frame_df.copy()\n",
    "\n",
    "total_frames = len(df)\n",
    "pose_frames = int(df[\"pose_detected\"].sum())\n",
    "\n",
    "# treat guard as \"down\" if wrist is a fair bit below shoulder\n",
    "guard_down_thresh = 0.15\n",
    "guard_down_frames = int(\n",
    "    ((df[\"left_guard_height\"] > guard_down_thresh) |\n",
    "     (df[\"right_guard_height\"] > guard_down_thresh)).sum()\n",
    ")\n",
    "\n",
    "round_stats = {\n",
    "    \"round_id\": \"round1\",  # later we’ll make this dynamic\n",
    "    \"total_frames\": total_frames,\n",
    "    \"pose_frames\": pose_frames,\n",
    "    \"pose_coverage\": pose_frames / total_frames if total_frames else 0.0,\n",
    "    \"guard_down_ratio\": guard_down_frames / pose_frames if pose_frames else 0.0,\n",
    "    \"avg_left_guard_height\":  float(df[\"left_guard_height\"].mean()),\n",
    "    \"avg_right_guard_height\": float(df[\"right_guard_height\"].mean()),\n",
    "    \"avg_hip_rotation\":       float(df[\"hip_rotation\"].mean()),\n",
    "    \"avg_stance_width\":       float(df[\"stance_width\"].mean()),\n",
    "    \"avg_head_y\":             float(df[\"head_y\"].mean()),\n",
    "}\n",
    "\n",
    "pd.Series(round_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "179412ff-0d39-4bc3-9117-63dcf095e0dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "round_id                             round1\n",
       "total_frames                          14095\n",
       "pose_frames                            8520\n",
       "pose_coverage                       0.60447\n",
       "guard_down_ratio                   0.010329\n",
       "avg_left_guard_height              0.031025\n",
       "avg_right_guard_height              0.03553\n",
       "avg_hip_rotation                    0.04255\n",
       "avg_stance_width                    0.04255\n",
       "avg_head_y                         0.630725\n",
       "video_danger_score                 0.164409\n",
       "video_form_score                   9.157296\n",
       "video_focus_next_round    pressure_and_body\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def video_form_and_danger(stats: dict) -> dict:\n",
    "    guard_down = stats[\"guard_down_ratio\"]          # 0–1\n",
    "    pose_cov   = stats[\"pose_coverage\"]            # 0–1\n",
    "\n",
    "    # higher danger if guard is down + low pose coverage\n",
    "    danger = 0.6 * guard_down + 0.4 * (1 - pose_cov)\n",
    "    danger = max(0.0, min(1.0, danger))\n",
    "\n",
    "    # form score starts at 10, subtract penalties\n",
    "    form = 10.0\n",
    "    form -= guard_down * 5.0       # big hit if guard down a lot\n",
    "    form -= (1 - pose_cov) * 2.0   # small hit if tracking low\n",
    "    form = max(0.0, min(10.0, form))\n",
    "\n",
    "    if danger >= 0.7:\n",
    "        focus = \"defense_first\"\n",
    "    elif danger >= 0.4:\n",
    "        focus = \"ring_cutting\"\n",
    "    else:\n",
    "        focus = \"pressure_and_body\"\n",
    "\n",
    "    out = stats.copy()\n",
    "    out[\"video_danger_score\"] = float(danger)\n",
    "    out[\"video_form_score\"] = float(form)\n",
    "    out[\"video_focus_next_round\"] = focus\n",
    "    return out\n",
    "\n",
    "round_enriched = video_form_and_danger(round_stats)\n",
    "pd.Series(round_enriched)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "046a4323-188c-401d-88f2-87917e6bcbd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Updated CSV: /opt/app-root/src/data/video_round_stats.csv\n",
      "✅ Saved JSON: /opt/app-root/src/ai_stats/round1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'round_id': 'round1',\n",
       " 'total_frames': 14095,\n",
       " 'pose_frames': 8520,\n",
       " 'pose_coverage': 0.6044696700957787,\n",
       " 'guard_down_ratio': 0.010328638497652582,\n",
       " 'avg_left_guard_height': 0.031024675537338,\n",
       " 'avg_right_guard_height': 0.03552993167751412,\n",
       " 'avg_hip_rotation': 0.0425502892426202,\n",
       " 'avg_stance_width': 0.0425502892426202,\n",
       " 'avg_head_y': 0.6307253441025673,\n",
       " 'video_danger_score': 0.1644093150602801,\n",
       " 'video_form_score': 9.157296147703295,\n",
       " 'video_focus_next_round': 'pressure_and_body'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "OUT_DATA = PROJECT_ROOT / \"data\"\n",
    "OUT_DATA.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# CSV of all rounds\n",
    "csv_path = OUT_DATA / \"video_round_stats.csv\"\n",
    "round_df = pd.DataFrame([round_enriched])\n",
    "\n",
    "if csv_path.exists():\n",
    "    existing = pd.read_csv(csv_path)\n",
    "    combined = pd.concat([existing, round_df], ignore_index=True)\n",
    "else:\n",
    "    combined = round_df\n",
    "\n",
    "combined.to_csv(csv_path, index=False)\n",
    "print(\"✅ Updated CSV:\", csv_path)\n",
    "\n",
    "# JSON (one per round) for ai_stats-style usage\n",
    "AI_STATS_DIR = PROJECT_ROOT / \"ai_stats\"\n",
    "AI_STATS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "json_path = AI_STATS_DIR / f\"{round_enriched['round_id']}.json\"\n",
    "with json_path.open(\"w\") as f:\n",
    "    json.dump(round_enriched, f, indent=2)\n",
    "\n",
    "print(\"✅ Saved JSON:\", json_path)\n",
    "round_enriched\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab49681c-9f9c-4d64-97ba-a7cbcbf65f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.risk_model import video_form_and_danger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739ac3bd-58d4-4394-9b21-db9d732fab32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
