{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b68dcc1-ccba-489f-bc12-79096185194b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: /opt/app-root/src/sammo-fight-iq\n",
      "DATA_DIR: /opt/app-root/src/sammo-fight-iq/data\n",
      "MODELS_DIR: /opt/app-root/src/sammo-fight-iq/models\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "MODELS_DIR = PROJECT_ROOT / \"models\"\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"DATA_DIR:\", DATA_DIR)\n",
    "print(\"MODELS_DIR:\", MODELS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bfd3313-a8cc-40d5-9d41-671c9f937984",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m danger_model = \u001b[43mjoblib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODELS_DIR\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdanger_predictor.joblib\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m focus_model  = joblib.load(MODELS_DIR / \u001b[33m\"\u001b[39m\u001b[33mfocus_predictor.joblib\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m feature_cols = joblib.load(MODELS_DIR / \u001b[33m\"\u001b[39m\u001b[33mfeature_columns.pkl\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/app-root/lib64/python3.12/site-packages/joblib/numpy_pickle.py:749\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(filename, mmap_mode, ensure_native_byte_order)\u001b[39m\n\u001b[32m    744\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m load_compatibility(fobj)\n\u001b[32m    746\u001b[39m             \u001b[38;5;66;03m# A memory-mapped array has to be mapped with the endianness\u001b[39;00m\n\u001b[32m    747\u001b[39m             \u001b[38;5;66;03m# it has been written with. Other arrays are coerced to the\u001b[39;00m\n\u001b[32m    748\u001b[39m             \u001b[38;5;66;03m# native endianness of the host system.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m749\u001b[39m             obj = \u001b[43m_unpickle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    750\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    751\u001b[39m \u001b[43m                \u001b[49m\u001b[43mensure_native_byte_order\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_native_byte_order\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    752\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    753\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmmap_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidated_mmap_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    754\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    756\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/app-root/lib64/python3.12/site-packages/joblib/numpy_pickle.py:626\u001b[39m, in \u001b[36m_unpickle\u001b[39m\u001b[34m(fobj, ensure_native_byte_order, filename, mmap_mode)\u001b[39m\n\u001b[32m    624\u001b[39m obj = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m     obj = \u001b[43munpickler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    627\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m unpickler.compat_mode:\n\u001b[32m    628\u001b[39m         warnings.warn(\n\u001b[32m    629\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mThe file \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m has been generated with a \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    630\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mjoblib version less than 0.10. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    633\u001b[39m             stacklevel=\u001b[32m3\u001b[39m,\n\u001b[32m    634\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib64/python3.12/pickle.py:1256\u001b[39m, in \u001b[36m_Unpickler.load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1254\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n\u001b[32m   1255\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, bytes_types)\n\u001b[32m-> \u001b[39m\u001b[32m1256\u001b[39m         \u001b[43mdispatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1257\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _Stop \u001b[38;5;28;01mas\u001b[39;00m stopinst:\n\u001b[32m   1258\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m stopinst.value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib64/python3.12/pickle.py:1581\u001b[39m, in \u001b[36m_Unpickler.load_stack_global\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1579\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(name) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mstr\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(module) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m   1580\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m UnpicklingError(\u001b[33m\"\u001b[39m\u001b[33mSTACK_GLOBAL requires str\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1581\u001b[39m \u001b[38;5;28mself\u001b[39m.append(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfind_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib64/python3.12/pickle.py:1622\u001b[39m, in \u001b[36m_Unpickler.find_class\u001b[39m\u001b[34m(self, module, name)\u001b[39m\n\u001b[32m   1620\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m _compat_pickle.IMPORT_MAPPING:\n\u001b[32m   1621\u001b[39m         module = _compat_pickle.IMPORT_MAPPING[module]\n\u001b[32m-> \u001b[39m\u001b[32m1622\u001b[39m \u001b[38;5;28;43m__import__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1623\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.proto >= \u001b[32m4\u001b[39m:\n\u001b[32m   1624\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _getattribute(sys.modules[module], name)[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/app-root/lib64/python3.12/site-packages/sklearn/__init__.py:82\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _distributor_init  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __check_build  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_show_versions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m show_versions\n\u001b[32m     85\u001b[39m __all__ = [\n\u001b[32m     86\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcalibration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     87\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcluster\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    128\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mshow_versions\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    129\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/app-root/lib64/python3.12/site-packages/sklearn/base.py:17\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _IS_32BIT\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_set_output\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _SetOutputMixin\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_tags\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     20\u001b[39m     _DEFAULT_TAGS,\n\u001b[32m     21\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/app-root/lib64/python3.12/site-packages/sklearn/utils/__init__.py:19\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m issparse\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmurmurhash\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m murmurhash3_32\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclass_weight\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compute_class_weight, compute_sample_weight\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _joblib\n",
      "\u001b[36mFile \u001b[39m\u001b[32msklearn/utils/murmurhash.pyx:1\u001b[39m, in \u001b[36minit sklearn.utils.murmurhash\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "danger_model = joblib.load(MODELS_DIR / \"danger_predictor.joblib\")\n",
    "focus_model  = joblib.load(MODELS_DIR / \"focus_predictor.joblib\")\n",
    "feature_cols = joblib.load(MODELS_DIR / \"feature_columns.pkl\")\n",
    "\n",
    "print(\"Loaded models and features:\")\n",
    "print(\"feature_cols:\", feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f6a7c26-3066-4af7-b0f4-ded46f3c2d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: /opt/app-root/src/sammo-fight-iq\n",
      "DATA_DIR: /opt/app-root/src/sammo-fight-iq/data\n",
      "MODELS_DIR: /opt/app-root/src/sammo-fight-iq/models\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "MODELS_DIR = PROJECT_ROOT / \"models\"\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"DATA_DIR:\", DATA_DIR)\n",
    "print(\"MODELS_DIR:\", MODELS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "784086b4-f5d5-4187-8718-44ab55203f48",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m danger_model = \u001b[43mjoblib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODELS_DIR\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdanger_predictor.joblib\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m focus_model  = joblib.load(MODELS_DIR / \u001b[33m\"\u001b[39m\u001b[33mfocus_predictor.joblib\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m feature_cols = joblib.load(MODELS_DIR / \u001b[33m\"\u001b[39m\u001b[33mfeature_columns.pkl\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/app-root/lib64/python3.12/site-packages/joblib/numpy_pickle.py:749\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(filename, mmap_mode, ensure_native_byte_order)\u001b[39m\n\u001b[32m    744\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m load_compatibility(fobj)\n\u001b[32m    746\u001b[39m             \u001b[38;5;66;03m# A memory-mapped array has to be mapped with the endianness\u001b[39;00m\n\u001b[32m    747\u001b[39m             \u001b[38;5;66;03m# it has been written with. Other arrays are coerced to the\u001b[39;00m\n\u001b[32m    748\u001b[39m             \u001b[38;5;66;03m# native endianness of the host system.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m749\u001b[39m             obj = \u001b[43m_unpickle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    750\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    751\u001b[39m \u001b[43m                \u001b[49m\u001b[43mensure_native_byte_order\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_native_byte_order\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    752\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    753\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmmap_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidated_mmap_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    754\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    756\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/app-root/lib64/python3.12/site-packages/joblib/numpy_pickle.py:626\u001b[39m, in \u001b[36m_unpickle\u001b[39m\u001b[34m(fobj, ensure_native_byte_order, filename, mmap_mode)\u001b[39m\n\u001b[32m    624\u001b[39m obj = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m     obj = \u001b[43munpickler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    627\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m unpickler.compat_mode:\n\u001b[32m    628\u001b[39m         warnings.warn(\n\u001b[32m    629\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mThe file \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m has been generated with a \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    630\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mjoblib version less than 0.10. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    633\u001b[39m             stacklevel=\u001b[32m3\u001b[39m,\n\u001b[32m    634\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib64/python3.12/pickle.py:1256\u001b[39m, in \u001b[36m_Unpickler.load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1254\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n\u001b[32m   1255\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, bytes_types)\n\u001b[32m-> \u001b[39m\u001b[32m1256\u001b[39m         \u001b[43mdispatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1257\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _Stop \u001b[38;5;28;01mas\u001b[39;00m stopinst:\n\u001b[32m   1258\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m stopinst.value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib64/python3.12/pickle.py:1581\u001b[39m, in \u001b[36m_Unpickler.load_stack_global\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1579\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(name) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mstr\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(module) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m   1580\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m UnpicklingError(\u001b[33m\"\u001b[39m\u001b[33mSTACK_GLOBAL requires str\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1581\u001b[39m \u001b[38;5;28mself\u001b[39m.append(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfind_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib64/python3.12/pickle.py:1622\u001b[39m, in \u001b[36m_Unpickler.find_class\u001b[39m\u001b[34m(self, module, name)\u001b[39m\n\u001b[32m   1620\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m _compat_pickle.IMPORT_MAPPING:\n\u001b[32m   1621\u001b[39m         module = _compat_pickle.IMPORT_MAPPING[module]\n\u001b[32m-> \u001b[39m\u001b[32m1622\u001b[39m \u001b[38;5;28;43m__import__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1623\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.proto >= \u001b[32m4\u001b[39m:\n\u001b[32m   1624\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _getattribute(sys.modules[module], name)[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/app-root/lib64/python3.12/site-packages/sklearn/__init__.py:82\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _distributor_init  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __check_build  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_show_versions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m show_versions\n\u001b[32m     85\u001b[39m __all__ = [\n\u001b[32m     86\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcalibration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     87\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcluster\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    128\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mshow_versions\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    129\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/app-root/lib64/python3.12/site-packages/sklearn/base.py:17\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _IS_32BIT\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_set_output\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _SetOutputMixin\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_tags\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     20\u001b[39m     _DEFAULT_TAGS,\n\u001b[32m     21\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/app-root/lib64/python3.12/site-packages/sklearn/utils/__init__.py:19\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m issparse\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmurmurhash\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m murmurhash3_32\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclass_weight\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compute_class_weight, compute_sample_weight\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _joblib\n",
      "\u001b[36mFile \u001b[39m\u001b[32msklearn/utils/murmurhash.pyx:1\u001b[39m, in \u001b[36minit sklearn.utils.murmurhash\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "danger_model = joblib.load(MODELS_DIR / \"danger_predictor.joblib\")\n",
    "focus_model  = joblib.load(MODELS_DIR / \"focus_predictor.joblib\")\n",
    "feature_cols = joblib.load(MODELS_DIR / \"feature_columns.pkl\")\n",
    "\n",
    "print(\"Loaded models and feature columns:\")\n",
    "print(\"feature_cols:\", feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47c56e90-5b11-437c-b82a-7394f1309002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/risk_model.py\n",
    "def video_form_and_danger(stats: dict) -> dict:\n",
    "    guard_down = stats[\"guard_down_ratio\"]\n",
    "    pose_cov   = stats[\"pose_coverage\"]\n",
    "\n",
    "    danger = 0.6 * guard_down + 0.4 * (1.0 - pose_cov)\n",
    "    danger = max(0.0, min(1.0, danger))\n",
    "\n",
    "    form = 10.0\n",
    "    form -= guard_down * 5.0\n",
    "    form -= (1.0 - pose_cov) * 2.0\n",
    "    form = max(0.0, min(10.0, form))\n",
    "\n",
    "    if danger >= 0.7:\n",
    "        focus = \"defense_first\"\n",
    "    elif danger >= 0.4:\n",
    "        focus = \"ring_cutting\"\n",
    "    else:\n",
    "        focus = \"pressure_and_body\"\n",
    "\n",
    "    out = dict(stats)\n",
    "    out[\"video_danger_score\"] = float(danger)\n",
    "    out[\"video_form_score\"] = float(form)\n",
    "    out[\"video_focus_next_round\"] = focus\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90a00d6c-013b-4cdf-a072-013b3c495306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting memlayer\n",
      "  Downloading memlayer-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-5.1.2-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: fastapi in /opt/app-root/lib64/python3.12/site-packages (0.116.1)\n",
      "Requirement already satisfied: uvicorn in /opt/app-root/lib64/python3.12/site-packages (0.34.0)\n",
      "Requirement already satisfied: requests in /opt/app-root/lib64/python3.12/site-packages (2.32.5)\n",
      "Requirement already satisfied: pydantic>=2.0.0 in /opt/app-root/lib64/python3.12/site-packages (from memlayer) (2.10.6)\n",
      "Collecting openai>=1.12.0 (from memlayer)\n",
      "  Downloading openai-2.8.1-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: numpy>=1.24.0 in /opt/app-root/lib64/python3.12/site-packages (from memlayer) (2.2.6)\n",
      "Collecting chromadb>=0.4.22 (from memlayer)\n",
      "  Downloading chromadb-1.3.5-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\n",
      "Collecting gqlalchemy>=1.5.0 (from memlayer)\n",
      "  Downloading gqlalchemy-1.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: networkx>=3.1 in /opt/app-root/lib64/python3.12/site-packages (from memlayer) (3.5)\n",
      "Collecting anthropic>=0.72.1 (from memlayer)\n",
      "  Downloading anthropic-0.74.1-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting google-genai>=1.50.0 (from memlayer)\n",
      "  Downloading google_genai-1.51.0-py3-none-any.whl.metadata (46 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.0 in /opt/app-root/lib64/python3.12/site-packages (from memlayer) (2.9.0.post0)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Downloading transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: tqdm in /opt/app-root/lib64/python3.12/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/app-root/lib64/python3.12/site-packages (from sentence-transformers) (2.7.1+cu128)\n",
      "Requirement already satisfied: scikit-learn in /opt/app-root/lib64/python3.12/site-packages (from sentence-transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in /opt/app-root/lib64/python3.12/site-packages (from sentence-transformers) (1.16.1)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Downloading huggingface_hub-1.1.5-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: Pillow in /opt/app-root/lib64/python3.12/site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /opt/app-root/lib64/python3.12/site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: filelock in /opt/app-root/lib64/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.19.1)\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/app-root/lib64/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/app-root/lib64/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading regex-2025.11.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/app-root/lib64/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.9.0)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: starlette<0.48.0,>=0.40.0 in /opt/app-root/lib64/python3.12/site-packages (from fastapi) (0.47.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/app-root/lib64/python3.12/site-packages (from pydantic>=2.0.0->memlayer) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/app-root/lib64/python3.12/site-packages (from pydantic>=2.0.0->memlayer) (2.27.2)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /opt/app-root/lib64/python3.12/site-packages (from starlette<0.48.0,>=0.40.0->fastapi) (4.10.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/app-root/lib64/python3.12/site-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/app-root/lib64/python3.12/site-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi) (1.3.1)\n",
      "Requirement already satisfied: click>=7.0 in /opt/app-root/lib64/python3.12/site-packages (from uvicorn) (8.1.8)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/app-root/lib64/python3.12/site-packages (from uvicorn) (0.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/app-root/lib64/python3.12/site-packages (from requests) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/app-root/lib64/python3.12/site-packages (from requests) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/app-root/lib64/python3.12/site-packages (from requests) (2025.8.3)\n",
      "Collecting distro<2,>=1.7.0 (from anthropic>=0.72.1->memlayer)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: docstring-parser<1,>=0.15 in /opt/app-root/lib64/python3.12/site-packages (from anthropic>=0.72.1->memlayer) (0.17.0)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in /opt/app-root/lib64/python3.12/site-packages (from anthropic>=0.72.1->memlayer) (0.28.1)\n",
      "Collecting jiter<1,>=0.4.0 (from anthropic>=0.72.1->memlayer)\n",
      "  Downloading jiter-0.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/app-root/lib64/python3.12/site-packages (from httpx<1,>=0.25.0->anthropic>=0.72.1->memlayer) (1.0.9)\n",
      "Collecting build>=1.0.3 (from chromadb>=0.4.22->memlayer)\n",
      "  Downloading build-1.3.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pybase64>=1.4.1 (from chromadb>=0.4.22->memlayer)\n",
      "  Downloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
      "Collecting posthog<6.0.0,>=2.4.0 (from chromadb>=0.4.22->memlayer)\n",
      "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb>=0.4.22->memlayer)\n",
      "  Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /opt/app-root/lib64/python3.12/site-packages (from chromadb>=0.4.22->memlayer) (1.36.0)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb>=0.4.22->memlayer)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.38.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /opt/app-root/lib64/python3.12/site-packages (from chromadb>=0.4.22->memlayer) (1.36.0)\n",
      "Collecting pypika>=0.48.9 (from chromadb>=0.4.22->memlayer)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting overrides>=7.3.1 (from chromadb>=0.4.22->memlayer)\n",
      "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting importlib-resources (from chromadb>=0.4.22->memlayer)\n",
      "  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /opt/app-root/lib64/python3.12/site-packages (from chromadb>=0.4.22->memlayer) (1.74.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /opt/app-root/lib64/python3.12/site-packages (from chromadb>=0.4.22->memlayer) (4.3.0)\n",
      "Collecting typer>=0.9.0 (from chromadb>=0.4.22->memlayer)\n",
      "  Downloading typer-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /opt/app-root/lib64/python3.12/site-packages (from chromadb>=0.4.22->memlayer) (30.1.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /opt/app-root/lib64/python3.12/site-packages (from chromadb>=0.4.22->memlayer) (8.5.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /opt/app-root/lib64/python3.12/site-packages (from chromadb>=0.4.22->memlayer) (5.2.0)\n",
      "Collecting orjson>=3.9.12 (from chromadb>=0.4.22->memlayer)\n",
      "  Downloading orjson-3.11.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/app-root/lib64/python3.12/site-packages (from chromadb>=0.4.22->memlayer) (13.9.4)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in /opt/app-root/lib64/python3.12/site-packages (from chromadb>=0.4.22->memlayer) (4.25.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/app-root/lib64/python3.12/site-packages (from posthog<6.0.0,>=2.4.0->chromadb>=0.4.22->memlayer) (1.17.0)\n",
      "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb>=0.4.22->memlayer)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb>=0.4.22->memlayer)\n",
      "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /opt/app-root/lib64/python3.12/site-packages (from google-genai>=1.50.0->memlayer) (2.40.3)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /opt/app-root/lib64/python3.12/site-packages (from google-genai>=1.50.0->memlayer) (15.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/app-root/lib64/python3.12/site-packages (from google-auth<3.0.0,>=2.14.1->google-genai>=1.50.0->memlayer) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/app-root/lib64/python3.12/site-packages (from google-auth<3.0.0,>=2.14.1->google-genai>=1.50.0->memlayer) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/app-root/lib64/python3.12/site-packages (from google-auth<3.0.0,>=2.14.1->google-genai>=1.50.0->memlayer) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/app-root/lib64/python3.12/site-packages (from rsa<5,>=3.1.4->google-auth<3.0.0,>=2.14.1->google-genai>=1.50.0->memlayer) (0.6.1)\n",
      "Collecting adlfs<2025.0.0,>=2023.9.0 (from gqlalchemy>=1.5.0->memlayer)\n",
      "  Downloading adlfs-2024.12.0-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting dacite<2.0.0,>=1.6.0 (from gqlalchemy>=1.5.0->memlayer)\n",
      "  Downloading dacite-1.9.2-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting neo4j<6.0.0,>=4.4.3 (from gqlalchemy>=1.5.0->memlayer)\n",
      "  Downloading neo4j-5.28.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting pandas<=2.2.3 (from gqlalchemy>=1.5.0->memlayer)\n",
      "  Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Requirement already satisfied: psutil<7.0,>=5.9 in /opt/app-root/lib64/python3.12/site-packages (from gqlalchemy>=1.5.0->memlayer) (5.9.8)\n",
      "Collecting pymgclient<2.0.0,>=1.3.1 (from gqlalchemy>=1.5.0->memlayer)\n",
      "  Downloading pymgclient-1.5.1.tar.gz (129 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting azure-core<2.0.0,>=1.28.0 (from adlfs<2025.0.0,>=2023.9.0->gqlalchemy>=1.5.0->memlayer)\n",
      "  Downloading azure_core-1.36.0-py3-none-any.whl.metadata (47 kB)\n",
      "Collecting azure-datalake-store<0.1,>=0.0.53 (from adlfs<2025.0.0,>=2023.9.0->gqlalchemy>=1.5.0->memlayer)\n",
      "  Downloading azure_datalake_store-0.0.53-py2.py3-none-any.whl.metadata (19 kB)\n",
      "Collecting azure-identity (from adlfs<2025.0.0,>=2023.9.0->gqlalchemy>=1.5.0->memlayer)\n",
      "  Downloading azure_identity-1.25.1-py3-none-any.whl.metadata (88 kB)\n",
      "Collecting azure-storage-blob>=12.17.0 (from adlfs<2025.0.0,>=2023.9.0->gqlalchemy>=1.5.0->memlayer)\n",
      "  Downloading azure_storage_blob-12.27.1-py3-none-any.whl.metadata (26 kB)\n",
      "Requirement already satisfied: aiohttp>=3.7.0 in /opt/app-root/lib64/python3.12/site-packages (from adlfs<2025.0.0,>=2023.9.0->gqlalchemy>=1.5.0->memlayer) (3.12.15)\n",
      "Requirement already satisfied: cffi in /opt/app-root/lib64/python3.12/site-packages (from azure-datalake-store<0.1,>=0.0.53->adlfs<2025.0.0,>=2023.9.0->gqlalchemy>=1.5.0->memlayer) (2.0.0)\n",
      "Collecting msal<2,>=1.16.0 (from azure-datalake-store<0.1,>=0.0.53->adlfs<2025.0.0,>=2023.9.0->gqlalchemy>=1.5.0->memlayer)\n",
      "  Downloading msal-1.34.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in /opt/app-root/lib64/python3.12/site-packages (from PyJWT[crypto]<3,>=1.0.0->msal<2,>=1.16.0->azure-datalake-store<0.1,>=0.0.53->adlfs<2025.0.0,>=2023.9.0->gqlalchemy>=1.5.0->memlayer) (2.10.1)\n",
      "Requirement already satisfied: cryptography<49,>=2.5 in /opt/app-root/lib64/python3.12/site-packages (from msal<2,>=1.16.0->azure-datalake-store<0.1,>=0.0.53->adlfs<2025.0.0,>=2023.9.0->gqlalchemy>=1.5.0->memlayer) (43.0.3)\n",
      "Requirement already satisfied: pytz in /opt/app-root/lib64/python3.12/site-packages (from neo4j<6.0.0,>=4.4.3->gqlalchemy>=1.5.0->memlayer) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/app-root/lib64/python3.12/site-packages (from pandas<=2.2.3->gqlalchemy>=1.5.0->memlayer) (2025.2)\n",
      "Collecting pyopenssl (from pymgclient<2.0.0,>=1.3.1->gqlalchemy>=1.5.0->memlayer)\n",
      "  Downloading pyopenssl-25.3.0-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/app-root/lib64/python3.12/site-packages (from aiohttp>=3.7.0->adlfs<2025.0.0,>=2023.9.0->gqlalchemy>=1.5.0->memlayer) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/app-root/lib64/python3.12/site-packages (from aiohttp>=3.7.0->adlfs<2025.0.0,>=2023.9.0->gqlalchemy>=1.5.0->memlayer) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/app-root/lib64/python3.12/site-packages (from aiohttp>=3.7.0->adlfs<2025.0.0,>=2023.9.0->gqlalchemy>=1.5.0->memlayer) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/app-root/lib64/python3.12/site-packages (from aiohttp>=3.7.0->adlfs<2025.0.0,>=2023.9.0->gqlalchemy>=1.5.0->memlayer) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/app-root/lib64/python3.12/site-packages (from aiohttp>=3.7.0->adlfs<2025.0.0,>=2023.9.0->gqlalchemy>=1.5.0->memlayer) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/app-root/lib64/python3.12/site-packages (from aiohttp>=3.7.0->adlfs<2025.0.0,>=2023.9.0->gqlalchemy>=1.5.0->memlayer) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/app-root/lib64/python3.12/site-packages (from aiohttp>=3.7.0->adlfs<2025.0.0,>=2023.9.0->gqlalchemy>=1.5.0->memlayer) (1.20.1)\n",
      "Collecting isodate>=0.6.1 (from azure-storage-blob>=12.17.0->adlfs<2025.0.0,>=2023.9.0->gqlalchemy>=1.5.0->memlayer)\n",
      "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: pycparser in /opt/app-root/lib64/python3.12/site-packages (from cffi->azure-datalake-store<0.1,>=0.0.53->adlfs<2025.0.0,>=2023.9.0->gqlalchemy>=1.5.0->memlayer) (2.23)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/app-root/lib64/python3.12/site-packages (from jsonschema>=4.19.0->chromadb>=0.4.22->memlayer) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/app-root/lib64/python3.12/site-packages (from jsonschema>=4.19.0->chromadb>=0.4.22->memlayer) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/app-root/lib64/python3.12/site-packages (from jsonschema>=4.19.0->chromadb>=0.4.22->memlayer) (0.27.1)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/app-root/lib64/python3.12/site-packages (from kubernetes>=28.1.0->chromadb>=0.4.22->memlayer) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/app-root/lib64/python3.12/site-packages (from kubernetes>=28.1.0->chromadb>=0.4.22->memlayer) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /opt/app-root/lib64/python3.12/site-packages (from kubernetes>=28.1.0->chromadb>=0.4.22->memlayer) (3.3.1)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb>=0.4.22->memlayer)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: flatbuffers in /opt/app-root/lib64/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb>=0.4.22->memlayer) (25.9.23)\n",
      "Requirement already satisfied: protobuf in /opt/app-root/lib64/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb>=0.4.22->memlayer) (4.25.8)\n",
      "Requirement already satisfied: sympy in /opt/app-root/lib64/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb>=0.4.22->memlayer) (1.14.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /opt/app-root/lib64/python3.12/site-packages (from opentelemetry-api>=1.2.0->chromadb>=0.4.22->memlayer) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /opt/app-root/lib64/python3.12/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb>=0.4.22->memlayer) (3.23.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in /opt/app-root/lib64/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.4.22->memlayer) (1.70.0)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.38.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.4.22->memlayer)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.38.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.38.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.4.22->memlayer)\n",
      "  Downloading opentelemetry_proto-1.38.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb>=0.4.22->memlayer)\n",
      "  Downloading opentelemetry_sdk-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb>=0.4.22->memlayer)\n",
      "  Downloading protobuf-6.33.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb>=0.4.22->memlayer)\n",
      "  Downloading opentelemetry_api-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.59b0 (from opentelemetry-sdk>=1.2.0->chromadb>=0.4.22->memlayer)\n",
      "  Downloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/app-root/lib64/python3.12/site-packages (from rich>=10.11.0->chromadb>=0.4.22->memlayer) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/app-root/lib64/python3.12/site-packages (from rich>=10.11.0->chromadb>=0.4.22->memlayer) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/app-root/lib64/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=0.4.22->memlayer) (0.1.2)\n",
      "Requirement already satisfied: setuptools in /opt/app-root/lib64/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (80.9.0)\n",
      "Requirement already satisfied: jinja2 in /opt/app-root/lib64/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.61 in /opt/app-root/lib64/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.57 in /opt/app-root/lib64/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.57 in /opt/app-root/lib64/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.7.1.26 in /opt/app-root/lib64/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (9.7.1.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.3.14 in /opt/app-root/lib64/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.3.14)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.41 in /opt/app-root/lib64/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (11.3.3.41)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.55 in /opt/app-root/lib64/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.9.55)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.2.55 in /opt/app-root/lib64/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (11.7.2.55)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.7.53 in /opt/app-root/lib64/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.5.7.53)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /opt/app-root/lib64/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /opt/app-root/lib64/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.55 in /opt/app-root/lib64/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.55)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.61 in /opt/app-root/lib64/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.0.11 in /opt/app-root/lib64/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.0.11)\n",
      "Requirement already satisfied: triton==3.3.1 in /opt/app-root/lib64/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/app-root/lib64/python3.12/site-packages (from sympy->onnxruntime>=1.14.1->chromadb>=0.4.22->memlayer) (1.3.0)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb>=0.4.22->memlayer)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /opt/app-root/lib64/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.4.22->memlayer) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /opt/app-root/lib64/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.4.22->memlayer) (1.1.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/app-root/lib64/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.4.22->memlayer) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /opt/app-root/lib64/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.4.22->memlayer) (1.1.0)\n",
      "Collecting msal-extensions>=1.2.0 (from azure-identity->adlfs<2025.0.0,>=2023.9.0->gqlalchemy>=1.5.0->memlayer)\n",
      "  Downloading msal_extensions-1.3.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb>=0.4.22->memlayer)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/app-root/lib64/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Collecting cryptography<49,>=2.5 (from msal<2,>=1.16.0->azure-datalake-store<0.1,>=0.0.53->adlfs<2025.0.0,>=2023.9.0->gqlalchemy>=1.5.0->memlayer)\n",
      "  Downloading cryptography-46.0.3-cp311-abi3-manylinux_2_34_x86_64.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/app-root/lib64/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/app-root/lib64/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Downloading memlayer-0.1.5-py3-none-any.whl (77 kB)\n",
      "Downloading sentence_transformers-5.1.2-py3-none-any.whl (488 kB)\n",
      "Downloading transformers-4.57.1-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m191.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m129.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m138.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading anthropic-0.74.1-py3-none-any.whl (371 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (361 kB)\n",
      "Downloading chromadb-1.3.5-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.4 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m21.4/21.4 MB\u001b[0m \u001b[31m103.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading build-1.3.0-py3-none-any.whl (23 kB)\n",
      "Downloading google_genai-1.51.0-py3-none-any.whl (260 kB)\n",
      "Downloading gqlalchemy-1.8.0-py3-none-any.whl (95 kB)\n",
      "Downloading adlfs-2024.12.0-py3-none-any.whl (41 kB)\n",
      "Downloading azure_core-1.36.0-py3-none-any.whl (213 kB)\n",
      "Downloading azure_datalake_store-0.0.53-py2.py3-none-any.whl (55 kB)\n",
      "Downloading dacite-1.9.2-py3-none-any.whl (16 kB)\n",
      "Downloading msal-1.34.0-py3-none-any.whl (116 kB)\n",
      "Downloading neo4j-5.28.2-py3-none-any.whl (313 kB)\n",
      "Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m120.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading azure_storage_blob-12.27.1-py3-none-any.whl (428 kB)\n",
      "Downloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
      "Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m110.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading openai-2.8.1-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m218.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.38.0-py3-none-any.whl (19 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.38.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.38.0-py3-none-any.whl (72 kB)\n",
      "Downloading opentelemetry_sdk-1.38.0-py3-none-any.whl (132 kB)\n",
      "Downloading opentelemetry_api-1.38.0-py3-none-any.whl (65 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl (207 kB)\n",
      "Downloading protobuf-6.33.1-cp39-abi3-manylinux2014_x86_64.whl (323 kB)\n",
      "Downloading orjson-3.11.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (136 kB)\n",
      "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Downloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
      "Downloading regex-2025.11.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (803 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m803.5/803.5 kB\u001b[0m \u001b[31m213.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (507 kB)\n",
      "Downloading typer-0.20.0-py3-none-any.whl (47 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading azure_identity-1.25.1-py3-none-any.whl (191 kB)\n",
      "Downloading msal_extensions-1.3.1-py3-none-any.whl (20 kB)\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Downloading pyopenssl-25.3.0-py3-none-any.whl (57 kB)\n",
      "Downloading cryptography-46.0.3-cp311-abi3-manylinux_2_34_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m96.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Building wheels for collected packages: pymgclient, pypika\n",
      "  Building wheel for pymgclient (pyproject.toml) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m\u001b[0m \u001b[32mBuilding wheel for pymgclient \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m>\u001b[0m \u001b[31m[22 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m /tmp/pip-build-env-7seb2k2k/overlay/lib/python3.12/site-packages/setuptools/dist.py:759: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         Please consider removing the following classifiers in favor of a SPDX license expression:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         License :: OSI Approved :: Apache Software License\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   self._finalize_license_expression()\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m Using static OpenSSL: True\n",
      "  \u001b[31m   \u001b[0m Checking if cmake3 can be used\n",
      "  \u001b[31m   \u001b[0m cmake3 is not accesible\n",
      "  \u001b[31m   \u001b[0m Checking if cmake can be used\n",
      "  \u001b[31m   \u001b[0m cmake is not accesible\n",
      "  \u001b[31m   \u001b[0m error: Cannot found suitable cmake\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[31m  ERROR: Failed building wheel for pymgclient\u001b[0m\u001b[31m\n",
      "\u001b[0m  Building wheel for pypika (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=f18b714a467a5016f500c2f9c93d608eae4b07e2fb1472c9fd911f007cbbbdb8\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-xkgjtp7i/wheels/d5/3d/69/8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n",
      "Successfully built pypika\n",
      "Failed to build pymgclient\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mfailed-wheel-build-for-install\u001b[0m\n",
      "\n",
      "\u001b[31m\u001b[0m Failed to build installable wheels for some pyproject.toml based projects\n",
      "\u001b[31m>\u001b[0m pymgclient\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install memlayer sentence-transformers fastapi uvicorn requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9956f250-84e4-4a31-aa6c-7c9b0d32fd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Created src/simple_memory.py\n"
     ]
    }
   ],
   "source": [
    "# Create src/simple_memory.py directly in notebook\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path(\"/opt/app-root/src/sammo-fight-iq\")\n",
    "PROJECT_ROOT.mkdir(exist_ok=True)\n",
    "(PROJECT_ROOT / \"src\").mkdir(exist_ok=True)\n",
    "\n",
    "simple_memory_code = '''import json\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "\n",
    "class SimpleMemoryStore:\n",
    "    \"\"\"Ultra-simple persistent memory using JSONL.\"\"\"\n",
    "    \n",
    "    def __init__(self, path: str = \"mem_store.jsonl\"):\n",
    "        self.path = Path(path)\n",
    "        self.path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        if not self.path.exists():\n",
    "            self.path.write_text(\"\")\n",
    "    \n",
    "    def append(self, agent_id: str, user_id: str, content: str):\n",
    "        record = {\"agent_id\": agent_id, \"user_id\": user_id, \"content\": content}\n",
    "        with self.path.open(\"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(json.dumps(record) + \"\\\\n\")\n",
    "    \n",
    "    def get_recent(self, agent_id: str, user_id: str, k: int = 5) -> List[str]:\n",
    "        if not self.path.exists():\n",
    "            return []\n",
    "        \n",
    "        lines = []\n",
    "        with self.path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if line:\n",
    "                    try:\n",
    "                        lines.append(json.loads(line))\n",
    "                    except json.JSONDecodeError:\n",
    "                        continue\n",
    "        \n",
    "        filtered = [\n",
    "            rec[\"content\"] for rec in lines\n",
    "            if rec.get(\"agent_id\") == agent_id and rec.get(\"user_id\") == user_id\n",
    "        ]\n",
    "        return filtered[-k:]\n",
    "'''\n",
    "\n",
    "(PROJECT_ROOT / \"src\" / \"simple_memory.py\").write_text(simple_memory_code)\n",
    "print(\" Created src/simple_memory.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d14ccded-45ab-4761-b5e6-af39f57fc010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Created src/llm_client.py\n"
     ]
    }
   ],
   "source": [
    "llm_client_code = '''from dataclasses import dataclass\n",
    "from typing import List, Dict\n",
    "import requests\n",
    "import os\n",
    "\n",
    "@dataclass\n",
    "class LLMConfig:\n",
    "    base_url: str\n",
    "    model: str\n",
    "    timeout: int = 60\n",
    "    temperature: float = 0.3\n",
    "\n",
    "class LocalLLMClient:\n",
    "    \"\"\"OpenAI-compatible client for local LLMs.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: LLMConfig):\n",
    "        self.config = config\n",
    "    \n",
    "    def complete(self, messages: List[Dict[str, str]]) -> str:\n",
    "        payload = {\n",
    "            \"model\": self.config.model,\n",
    "            \"messages\": messages,\n",
    "            \"temperature\": self.config.temperature,\n",
    "            \"max_tokens\": 1024,\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            resp = requests.post(self.config.base_url, json=payload, timeout=self.config.timeout)\n",
    "            resp.raise_for_status()\n",
    "            data = resp.json()\n",
    "            \n",
    "            if \"choices\" in data:\n",
    "                return data[\"choices\"][0][\"message\"][\"content\"]\n",
    "            elif \"response\" in data:\n",
    "                return data[\"response\"]\n",
    "            else:\n",
    "                raise ValueError(f\"Unexpected response: {data}\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            return f\"[LLM Error: {str(e)}]\"\n",
    "\n",
    "def get_llm_config() -> LLMConfig:\n",
    "    return LLMConfig(\n",
    "        base_url=os.getenv(\"LLM_BASE_URL\", \"http://localhost:11434/v1/chat/completions\"),\n",
    "        model=os.getenv(\"LLM_MODEL\", \"mistral:7b-instruct\"),\n",
    "    )\n",
    "'''\n",
    "\n",
    "(PROJECT_ROOT / \"src\" / \"llm_client.py\").write_text(llm_client_code)\n",
    "print(\" Created src/llm_client.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66ff8c3b-ee68-40fa-856e-879f6d6f9889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Created src/memory_layer.py\n"
     ]
    }
   ],
   "source": [
    "memory_layer_code = '''from typing import Optional, Dict\n",
    "import json\n",
    "from .llm_client import LocalLLMClient\n",
    "from .simple_memory import SimpleMemoryStore\n",
    "\n",
    "class MemoryBackedLLM:\n",
    "    \"\"\"LLM with persistent conversation memory.\"\"\"\n",
    "    \n",
    "    def __init__(self, llm_client: LocalLLMClient, mem_path: str = \"mem_data/mem_store.jsonl\"):\n",
    "        self.llm = llm_client\n",
    "        self.store = SimpleMemoryStore(mem_path)\n",
    "    \n",
    "    def chat(self, agent_id: str, user_id: str, system_prompt: str, \n",
    "             message: str, context_data: Optional[Dict] = None) -> str:\n",
    "        \n",
    "        # Get recent history\n",
    "        history_chunks = self.store.get_recent(agent_id, user_id, k=5)\n",
    "        history_text = \"\\\\n\".join(history_chunks)\n",
    "        \n",
    "        # Build messages\n",
    "        messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "        \n",
    "        if history_text:\n",
    "            messages.append({\"role\": \"system\", \"content\": f\"Recent history:\\\\n{history_text}\"})\n",
    "        \n",
    "        if context_data:\n",
    "            messages.append({\"role\": \"system\", \"content\": f\"Current stats:\\\\n{json.dumps(context_data, indent=2)}\"})\n",
    "        \n",
    "        messages.append({\"role\": \"user\", \"content\": message})\n",
    "        \n",
    "        # Get response\n",
    "        reply = self.llm.complete(messages)\n",
    "        \n",
    "        # Store interaction\n",
    "        self.store.append(agent_id, user_id, f\"User: {message}\\\\nCoach: {reply}\")\n",
    "        \n",
    "        return reply\n",
    "'''\n",
    "\n",
    "(PROJECT_ROOT / \"src\" / \"memory_layer.py\").write_text(memory_layer_code)\n",
    "print(\" Created src/memory_layer.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2a16515-477b-411f-a764-e7c49228eb53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Created boxing coach\n"
     ]
    }
   ],
   "source": [
    "# Create agents directory\n",
    "(PROJECT_ROOT / \"src\" / \"agents\").mkdir(exist_ok=True)\n",
    "\n",
    "# __init__.py\n",
    "(PROJECT_ROOT / \"src\" / \"agents\" / \"__init__.py\").write_text(\"from .boxing_coach import BoxingCoach\\n\")\n",
    "\n",
    "# base_coach.py\n",
    "base_coach_code = '''from typing import Optional, Dict\n",
    "from ..memory_layer import MemoryBackedLLM\n",
    "\n",
    "class BaseCoach:\n",
    "    agent_id: str = \"generic\"\n",
    "    \n",
    "    def __init__(self, mem_llm: MemoryBackedLLM, system_prompt: str):\n",
    "        self.mem_llm = mem_llm\n",
    "        self.system_prompt = system_prompt\n",
    "    \n",
    "    def chat(self, user_id: str, message: str, context_data: Optional[Dict] = None) -> str:\n",
    "        return self.mem_llm.chat(self.agent_id, user_id, self.system_prompt, message, context_data)\n",
    "'''\n",
    "\n",
    "(PROJECT_ROOT / \"src\" / \"agents\" / \"base_coach.py\").write_text(base_coach_code)\n",
    "\n",
    "# boxing_coach.py\n",
    "boxing_coach_code = '''from .base_coach import BaseCoach\n",
    "\n",
    "BOXING_SYSTEM_PROMPT = \"\"\"You are SAMMO Fight IQ, an elite boxing coach.\n",
    "\n",
    "Fighter: Nolan, 47, 5'7\" pressure fighter (Foreman/Pitbull Cruz style)\n",
    "Goals: Sustainable pressure, guard discipline, smarter body work\n",
    "\n",
    "Your style:\n",
    "- SAFETY FIRST - flag defensive vulnerabilities immediately\n",
    "- Short, concrete feedback (2-3 actionable cues)\n",
    "- Use metrics when provided (danger_score, guard_down_ratio, etc.)\n",
    "- Honest assessment, no fluff\n",
    "- Connect flaws to consequences\n",
    "\n",
    "When analyzing stats:\n",
    "- danger_score > 0.6 = HIGH RISK\n",
    "- guard_down_ratio > 30% = dangerous habit\n",
    "- form_score < 0.7 = technique breakdown\n",
    "- focus_next_round = training priority\n",
    "\n",
    "Response format:\n",
    "1. What the data shows (specific)\n",
    "2. The immediate risk/opportunity\n",
    "3. 1-2 concrete drills to fix it\n",
    "4. Reference past sessions when relevant\n",
    "\n",
    "You're building a fighter who can defend themselves safely.\"\"\"\n",
    "\n",
    "class BoxingCoach(BaseCoach):\n",
    "    agent_id = \"boxing\"\n",
    "    \n",
    "    def __init__(self, mem_llm):\n",
    "        super().__init__(mem_llm, system_prompt=BOXING_SYSTEM_PROMPT)\n",
    "'''\n",
    "\n",
    "(PROJECT_ROOT / \"src\" / \"agents\" / \"boxing_coach.py\").write_text(boxing_coach_code)\n",
    "print(\" Created boxing coach\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "377d0a05-7e1e-4fc6-acc6-f6724ea1eecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " All core files created\n",
      "\n",
      " Project structure:\n",
      "   /opt/app-root/src/sammo-fight-iq\n",
      "    src/\n",
      "       simple_memory.py\n",
      "       llm_client.py\n",
      "       memory_layer.py\n",
      "       agents/\n",
      "           base_coach.py\n",
      "           boxing_coach.py\n",
      "    data/\n",
      "    mem_data/\n"
     ]
    }
   ],
   "source": [
    "# src/__init__.py\n",
    "(PROJECT_ROOT / \"src\" / \"__init__.py\").write_text(\"\")\n",
    "\n",
    "print(\" All core files created\")\n",
    "print(f\"\\n Project structure:\")\n",
    "print(f\"   {PROJECT_ROOT}\")\n",
    "print(f\"    src/\")\n",
    "print(f\"       simple_memory.py\")\n",
    "print(f\"       llm_client.py\")\n",
    "print(f\"       memory_layer.py\")\n",
    "print(f\"       agents/\")\n",
    "print(f\"           base_coach.py\")\n",
    "print(f\"           boxing_coach.py\")\n",
    "print(f\"    data/\")\n",
    "print(f\"    mem_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cf070b1-4ab7-4bf7-9571-d14f53fbbf96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Memory store works!\n",
      "   Stored and retrieved 1 entries\n",
      "   Last entry: User: Test message\n",
      "Coach: Test response...\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from src.simple_memory import SimpleMemoryStore\n",
    "\n",
    "# Test memory store\n",
    "mem_store = SimpleMemoryStore(str(PROJECT_ROOT / \"mem_data\" / \"test.jsonl\"))\n",
    "\n",
    "# Store test data\n",
    "mem_store.append(\"boxing\", \"nolan\", \"User: Test message\\nCoach: Test response\")\n",
    "\n",
    "# Retrieve\n",
    "history = mem_store.get_recent(\"boxing\", \"nolan\", k=5)\n",
    "\n",
    "print(\" Memory store works!\")\n",
    "print(f\"   Stored and retrieved {len(history)} entries\")\n",
    "print(f\"   Last entry: {history[-1][:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4dc6f184-739f-40cb-ab0e-e15796392caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Round stats loaded:\n",
      "  round_id  total_frames  pose_frames  pose_coverage  guard_down_ratio  \\\n",
      "0   round1         14095         8520        0.60447          0.010329   \n",
      "\n",
      "   avg_left_guard_height  avg_right_guard_height  avg_hip_rotation  \\\n",
      "0               0.031025                 0.03553           0.04255   \n",
      "\n",
      "   avg_stance_width  avg_head_y  video_danger_score  video_form_score  \\\n",
      "0           0.04255    0.630725            0.164409          9.157296   \n",
      "\n",
      "  video_focus_next_round  \n",
      "0      pressure_and_body  \n",
      "\n",
      " Round 1 data:\n",
      "   round_id: round1\n",
      "   total_frames: 14095\n",
      "   pose_frames: 8520\n",
      "   pose_coverage: 0.604\n",
      "   guard_down_ratio: 0.010\n",
      "   avg_left_guard_height: 0.031\n",
      "   avg_right_guard_height: 0.036\n",
      "   avg_hip_rotation: 0.043\n",
      "   avg_stance_width: 0.043\n",
      "   avg_head_y: 0.631\n",
      "   video_danger_score: 0.164\n",
      "   video_form_score: 9.157\n",
      "   video_focus_next_round: pressure_and_body\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path(\"/opt/app-root/src/sammo-fight-iq\")\n",
    "\n",
    "# Files are in different locations - let's use the actual paths\n",
    "CSV_PATH = Path(\"/opt/app-root/src/data/video_round_stats.csv\")\n",
    "JSON_PATH = Path(\"/opt/app-root/src/ai_stats/round1.json\")\n",
    "\n",
    "# Load round stats\n",
    "try:\n",
    "    round_stats = pd.read_csv(CSV_PATH)\n",
    "    print(\" Round stats loaded:\")\n",
    "    print(round_stats)\n",
    "    print()\n",
    "except FileNotFoundError:\n",
    "    print(f\" {CSV_PATH} not found\")\n",
    "    round_stats = None\n",
    "\n",
    "# Load round1.json\n",
    "try:\n",
    "    with open(JSON_PATH) as f:\n",
    "        round1 = json.load(f)\n",
    "    \n",
    "    print(\" Round 1 data:\")\n",
    "    for key, value in round1.items():\n",
    "        if isinstance(value, float):\n",
    "            print(f\"   {key}: {value:.3f}\")\n",
    "        else:\n",
    "            print(f\"   {key}: {value}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\" {JSON_PATH} not found\")\n",
    "    round1 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0909ff9d-8718-49ca-9de3-eb92d63b16ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Searching for data files...\n",
      "\n",
      " Found video_round_stats.csv:\n",
      "   /opt/app-root/src/data/video_round_stats.csv\n",
      " Found round1.json:\n",
      "   /opt/app-root/src/ai_stats/round1.json\n",
      " Found video_round_stats.csv:\n",
      "   /opt/app-root/src/data/video_round_stats.csv\n",
      " Found round1.json:\n",
      "   /opt/app-root/src/ai_stats/round1.json\n",
      "\n",
      " Current directory: /opt/app-root/src/sammo-fight-iq/notebooks\n",
      " Files here: [PosixPath('/opt/app-root/src/sammo-fight-iq/notebooks/.ipynb_checkpoints'), PosixPath('/opt/app-root/src/sammo-fight-iq/notebooks/01_pose_detection_test.ipynb'), PosixPath('/opt/app-root/src/sammo-fight-iq/notebooks/02_video_processing.ipynb'), PosixPath('/opt/app-root/src/sammo-fight-iq/notebooks/03_model_inference_test.ipynb'), PosixPath('/opt/app-root/src/sammo-fight-iq/notebooks/Untitled.ipynb')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Search for the files\n",
    "print(\" Searching for data files...\\n\")\n",
    "\n",
    "# Check common locations\n",
    "search_paths = [\n",
    "    Path(\"/opt/app-root/src/sammo-fight-iq\"),\n",
    "    Path(\"/opt/app-root/src\"),\n",
    "    Path.home(),\n",
    "]\n",
    "\n",
    "for search_path in search_paths:\n",
    "    if search_path.exists():\n",
    "        # Search for CSV\n",
    "        csv_files = list(search_path.rglob(\"video_round_stats.csv\"))\n",
    "        json_files = list(search_path.rglob(\"round1.json\"))\n",
    "        \n",
    "        if csv_files:\n",
    "            print(f\" Found video_round_stats.csv:\")\n",
    "            for f in csv_files:\n",
    "                print(f\"   {f}\")\n",
    "        \n",
    "        if json_files:\n",
    "            print(f\" Found round1.json:\")\n",
    "            for f in json_files:\n",
    "                print(f\"   {f}\")\n",
    "\n",
    "# Also check current working directory\n",
    "print(f\"\\n Current directory: {Path.cwd()}\")\n",
    "print(f\" Files here: {list(Path.cwd().glob('*'))[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8fae583d-99c3-40ab-a4c4-7bef93dbbcf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Copied CSV to /opt/app-root/src/sammo-fight-iq/data/video_round_stats.csv\n",
      " Copied JSON to /opt/app-root/src/sammo-fight-iq/data/round1.json\n",
      "\n",
      " All data files now in project directory\n"
     ]
    }
   ],
   "source": [
    "# Copy files to project data directory\n",
    "import shutil\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Copy CSV\n",
    "shutil.copy(CSV_PATH, DATA_DIR / \"video_round_stats.csv\")\n",
    "print(f\" Copied CSV to {DATA_DIR / 'video_round_stats.csv'}\")\n",
    "\n",
    "# Copy JSON\n",
    "shutil.copy(JSON_PATH, DATA_DIR / \"round1.json\")\n",
    "print(f\" Copied JSON to {DATA_DIR / 'round1.json'}\")\n",
    "\n",
    "# Now you can use the project paths\n",
    "round_stats = pd.read_csv(DATA_DIR / \"video_round_stats.csv\")\n",
    "with open(DATA_DIR / \"round1.json\") as f:\n",
    "    round1 = json.load(f)\n",
    "\n",
    "print(\"\\n All data files now in project directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75064802-ee10-48f5-a6b9-622562dde3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Boxing coach initialized (MOCK MODE)\n"
     ]
    }
   ],
   "source": [
    "from src.llm_client import LLMConfig, LocalLLMClient\n",
    "from src.memory_layer import MemoryBackedLLM\n",
    "from src.agents import BoxingCoach\n",
    "\n",
    "# Mock LLM that doesn't need a server\n",
    "class MockLLMClient:\n",
    "    \"\"\"Mock LLM for testing without server.\"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "    \n",
    "    def complete(self, messages):\n",
    "        # Simple mock response based on context\n",
    "        user_msg = messages[-1][\"content\"].lower()\n",
    "        \n",
    "        # Check if stats are in context\n",
    "        has_stats = any(\"danger_score\" in str(m.get(\"content\", \"\")) for m in messages)\n",
    "        \n",
    "        if has_stats:\n",
    "            return \"\"\"Looking at your stats:\n",
    "\n",
    "Your danger score of 0.65 is in the MODERATE-HIGH risk zone. The main issue I'm seeing is guard discipline - you're dropping it 38% of the time.\n",
    "\n",
    "Your left guard is averaging 0.42 (should be 0.55+). When you throw combinations, you're leaving your head exposed.\n",
    "\n",
    "Fix this with the 'punch-and-return' drill:\n",
    "- 3 rounds on the heavy bag\n",
    "- Every combo MUST end with hands back to face\n",
    "- Focus on form, not power\n",
    "- Video yourself and watch for guard drops\n",
    "\n",
    "Hip rotation at 28 is weak - wider stance + resistance band work will help.\"\"\"\n",
    "        else:\n",
    "            return \"\"\"Hey! Ready to work. Upload a round or tell me what you want to focus on today.\n",
    "\n",
    "Remember from last time - we were working on guard discipline and hip rotation.\"\"\"\n",
    "\n",
    "# Initialize with mock\n",
    "llm_config = LLMConfig(base_url=\"mock\", model=\"mock\")\n",
    "llm_client = MockLLMClient(llm_config)\n",
    "memory_llm = MemoryBackedLLM(llm_client, mem_path=str(PROJECT_ROOT / \"mem_data\" / \"mem_store.jsonl\"))\n",
    "boxing_coach = BoxingCoach(memory_llm)\n",
    "\n",
    "print(\" Boxing coach initialized (MOCK MODE)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1d525d1-7f84-412d-99fc-1a0f919e92ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SAMMO:\n",
      "Looking at your stats:\n",
      "\n",
      "Your danger score of 0.65 is in the MODERATE-HIGH risk zone. The main issue I'm seeing is guard discipline - you're dropping it 38% of the time.\n",
      "\n",
      "Your left guard is averaging 0.42 (should be 0.55+). When you throw combinations, you're leaving your head exposed.\n",
      "\n",
      "Fix this with the 'punch-and-return' drill:\n",
      "- 3 rounds on the heavy bag\n",
      "- Every combo MUST end with hands back to face\n",
      "- Focus on form, not power\n",
      "- Video yourself and watch for guard drops\n",
      "\n",
      "Hip rotation at 28 is weak - wider stance + resistance band work will help.\n",
      "\n",
      "============================================================\n",
      "\n",
      " SAMMO (analyzing Round 1):\n",
      "Looking at your stats:\n",
      "\n",
      "Your danger score of 0.65 is in the MODERATE-HIGH risk zone. The main issue I'm seeing is guard discipline - you're dropping it 38% of the time.\n",
      "\n",
      "Your left guard is averaging 0.42 (should be 0.55+). When you throw combinations, you're leaving your head exposed.\n",
      "\n",
      "Fix this with the 'punch-and-return' drill:\n",
      "- 3 rounds on the heavy bag\n",
      "- Every combo MUST end with hands back to face\n",
      "- Focus on form, not power\n",
      "- Video yourself and watch for guard drops\n",
      "\n",
      "Hip rotation at 28 is weak - wider stance + resistance band work will help.\n",
      "\n",
      "============================================================\n",
      "\n",
      " SAMMO (follow-up):\n",
      "Looking at your stats:\n",
      "\n",
      "Your danger score of 0.65 is in the MODERATE-HIGH risk zone. The main issue I'm seeing is guard discipline - you're dropping it 38% of the time.\n",
      "\n",
      "Your left guard is averaging 0.42 (should be 0.55+). When you throw combinations, you're leaving your head exposed.\n",
      "\n",
      "Fix this with the 'punch-and-return' drill:\n",
      "- 3 rounds on the heavy bag\n",
      "- Every combo MUST end with hands back to face\n",
      "- Focus on form, not power\n",
      "- Video yourself and watch for guard drops\n",
      "\n",
      "Hip rotation at 28 is weak - wider stance + resistance band work will help.\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Simple greeting\n",
    "response = boxing_coach.chat(\n",
    "    user_id=\"nolan\",\n",
    "    message=\"Hey coach, ready to review my round?\"\n",
    ")\n",
    "\n",
    "print(\" SAMMO:\")\n",
    "print(response)\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Test 2: With round data (if available)\n",
    "if round1:\n",
    "    response = boxing_coach.chat(\n",
    "        user_id=\"nolan\",\n",
    "        message=\"What did you see in my last round? What should I focus on?\",\n",
    "        context_data=round1\n",
    "    )\n",
    "    \n",
    "    print(\" SAMMO (analyzing Round 1):\")\n",
    "    print(response)\n",
    "    print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Test 3: Follow-up (tests memory)\n",
    "response = boxing_coach.chat(\n",
    "    user_id=\"nolan\",\n",
    "    message=\"Remind me what drill you said to do?\"\n",
    ")\n",
    "\n",
    "print(\" SAMMO (follow-up):\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7995e4-4ef3-43df-8f13-379a40cf6fb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
